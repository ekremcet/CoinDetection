# -*- coding: utf-8 -*-
"""CoinDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hNbYALZQ7x98LETNAxWaiG__zSrehOmz

# Preparing the Collab

**Install Required Libraries**
"""

# http://pytorch.org/
from os.path import exists
from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag
platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())
cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\.\([0-9]*\)\.\([0-9]*\)$/cu\1\2/'
accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'

!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision
!pip install pillow==4.1.1
# %reload_ext autoreload
# %autoreload

"""**Import the Data into Collab**"""

from google.colab import drive
drive.mount('/content/drive')

"""# Initializing and Training Model

**Imports**
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import torch.nn.functional as F
from torch import nn
from torch import optim
from torchvision import datasets, transforms
from torch.autograd import Variable
from torch.utils.data.sampler import SubsetRandomSampler

"""**Data Paths and Constants**"""

TRAIN_DIR = '/content/drive/My Drive/TrainData'
TEST_DIR = '/content/drive/My Drive/TestData'
IMG_SIZE = 256

"""**Helper Function to Load Data**"""

def load_data(data_dir):
    data_transforms = transforms.Compose([transforms.Resize(IMG_SIZE), transforms.ToTensor(), ]) # Define the transform: Resize the image and convert to Tensor
    data_folder = datasets.ImageFolder(data_dir, transform=data_transforms) 

    num_train = len(data_folder)
    indices = list(range(num_train))
    np.random.shuffle(indices) # Randomly select samples at each batch
    sampler = SubsetRandomSampler(indices)
    data = torch.utils.data.DataLoader(data_folder, sampler=sampler, batch_size=64) # Define a data loader, 64 images will be fed to network at each step

    return data

"""**Define the Network**"""

class ConvNet(nn.Module):
    def __init__(self):
        super(ConvNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 61 * 61, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 3)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x))) # Conv -> ReLU -> MaxPool
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.size(0), 16 * 61 * 61) # This flattens the output (16, 61, 61) -> 59536
        x = F.relu(self.fc1(x)) # Fully Connected Layer -> ReLU
        x = F.relu(self.fc2(x))
        x = self.fc3(x)

        return x

model = ConvNet()
print(model)

"""Conv2d(3, 6, 5) means that the input will have 3 channels, there will be 6 output channels and 5x5 kernel will be applied to image. <br>
After each convolution we need some non-linearity and we impose that with activation functions.<br>
We used **ReLU** as the activation function.


---


![alt text](https://www.researchgate.net/profile/Leo_Pauly/publication/319235847/figure/fig3/AS:537056121634820@1505055565670/ReLU-activation-function.png)


---

**Train the Model**
"""

train_data = load_data(TRAIN_DIR)

# Initialize Model and Optimizers
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
criterion = nn.CrossEntropyLoss() # CrossEntrpoy is used as loss
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # Optimization is done by Stochastic Gradient Descent
losses = []
for epoch in range(50):
    running_loss = 0.0
    for i, data in enumerate(train_data, 0):
        inputs, labels = data # take batch of data
        optimizer.zero_grad()

        outputs = model(inputs) # feed the batch to model and get outputs
        loss = criterion(outputs, labels) # calculate the loss 
        loss.backward() # back propogate the loss
        optimizer.step() # take the optimization step

        # print statistics
        running_loss += loss.item() # calculate the loss for current batch
        if i % 4 == 3:
            print('Epoch: %d loss: %.3f' %
                  (epoch + 1, running_loss / 3))
            losses.append(running_loss / 3)
            running_loss = 0.0

print('Finished Training')

"""**Loss Graph**"""

fig = plt.figure(figsize=(10,10))
plt.plot(np.arange(1, len(losses) + 1), losses)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Epoch - Loss Graph")
plt.show()

"""# Testing the Model
**Test the Model and Print Accuracy**
"""

test_data = load_data(TEST_DIR)
# Test Model
correct = 0
total = 0
with torch.no_grad():
    for data in test_data:
        images, labels = data
        outputs = model(images) # get the output from model
        _, predicted = torch.max(outputs.data, 1) # take the max as result
        total += labels.size(0)
        correct += (predicted == labels).sum().item() 

print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))

"""**Functions to Display Examples**"""

test_transforms = transforms.Compose([transforms.Resize(IMG_SIZE), transforms.ToTensor(), ])

def predict_image(image):
    image_tensor = test_transforms(image).float()
    image_tensor = image_tensor.unsqueeze_(0)
    input = Variable(image_tensor)
    input = input.to(device)
    output = model(input)
    index = output.data.cpu().numpy().argmax()
    
    return index


def get_random_images(num):
    data = datasets.ImageFolder(TEST_DIR, transform=test_transforms)
    indices = list(range(len(data)))
    np.random.shuffle(indices)
    idx = indices[:num]
    sampler = SubsetRandomSampler(idx)
    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)
    dataiter = iter(loader)
    images, labels = dataiter.next()

    return images, labels

"""**Display Test Results**"""

classes = ["Chinese", "Ottoman", "Roman"]
to_pil = transforms.ToPILImage()
images, labels = get_random_images(30) # There are 30 test images
fig = plt.figure(figsize=(20,20))
fig.subplots_adjust(wspace=0, hspace=0.2)

for i in range(len(images)):
    image = to_pil(images[i])
    label_index = predict_image(image)
    sub = fig.add_subplot(5, 6, i+1)
    res = int(labels[i]) == label_index  # Prediction result
    bgc = "g" if res else "r"
    sub.set_title(str(classes[label_index]), fontsize="large",fontweight="bold",
                  color="white", backgroundcolor=bgc)
    plt.axis('off')
    plt.imshow(image)

plt.show()